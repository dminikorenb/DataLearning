{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# conda install nltk \n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.scorer import SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    movie_reviews.categories()\n",
    "except:\n",
    "    import nltk\n",
    "    print('This appears to be your first time using the NLTK Movie Reviews corpus. We will first download the necessary corpus (this is a one-time download that might take a little while')\n",
    "    nltk.download('movie_reviews')\n",
    "#     from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer(num, answer):\n",
    "    with open(\"dminik6_p4_w1_{}.txt\".format(num), \"w\") as fout:\n",
    "        fout.write(str(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создайте список из текстов всех имеющихся отзывов, а также список с классами, которые будет использовать ваш классификатор - 0 для негативных отзывов и 1 для позитивных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы получить id-шники негативных и позитивных отзывов:\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negfeats = [\" \".join(movie_reviews.words(fileids=[f])) for f in negids]\n",
    "posfeats = [\" \".join(movie_reviews.words(fileids=[f])) for f in posids]\n",
    "\n",
    "texts = negfeats + posfeats\n",
    "labels = [0] * len(negfeats) + [1] * len(posfeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.nltk.org/book/ch06.html#document-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Подсчитайте количество отзывов в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Количество отзывов в выборке:2000\n"
     ]
    }
   ],
   "source": [
    "ans_1 = len(negids) + len(posids)\n",
    "print('1. Количество отзывов в выборке:{}'.format(ans_1))\n",
    "write_answer(1, ans_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(texts[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Подсчитайте долю класса 1 в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Доля класса 1 в выборке:0.5\n"
     ]
    }
   ],
   "source": [
    "ans_2 = len(posfeats) / (ans_1)\n",
    "print('2. Доля класса 1 в выборке:{}'.format(ans_2))\n",
    "write_answer(2, ans_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Импортируйте CountVectorizer из sklearn.feature_extraction.text. Попробуйте использовать его с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста. Скорее всего, попытка не увенчается успехом. Разберитесь, в чем причина, и добейтесь того, чтобы метод fit_transform у CountVectorizer успешно отрабатывал. Подсчитайте количество признаков в CountVectorizer. Никакой предварительной обработки текста (удаление стоп-слов, нормализация слов) на этом шаге делать не надо, в качестве признаков должны использоваться частоты слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Количество признаков в CountVectorizer со стандартными настройками: 39659\n",
      "39659\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(texts)\n",
    "ans_3 = X.shape[1]\n",
    "print('3. Количество признаков в CountVectorizer со стандартными настройками: {}'.format(ans_3))\n",
    "print(len(cv.get_feature_names()))\n",
    "write_answer(3, ans_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Соберите pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию и с помощью cross_val_score (также со стандартными настройками) оцените получаемое \"из коробки\" качество по accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])\n"
     ]
    }
   ],
   "source": [
    "# Прежде чем начать работать с качеством, посмотрим какие \"оенщики\" есть \n",
    "print(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "# По умолчанию scoring устанавливаетмя в значение accuracy. Но можно и написать явно \n",
    "accuracy = cross_val_score(pipeline, texts, labels, cv=3, scoring='accuracy' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81437126 0.84684685 0.84684685]\n",
      "4. Accuracy в кросс-валидации: 0.8360216503929078\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "ans_4 = accuracy.mean()\n",
    "print('4. Accuracy в кросс-валидации: {}'.format(ans_4))\n",
    "write_answer(4, ans_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Аналогично accuracy, оцените качество по ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = cross_val_score(pipeline, texts, labels, scoring='roc_auc', cv=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9006239  0.91283175 0.91887383]\n",
      "5. ROC AUC в кросс-валидации: 0.9107764937833774\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc)\n",
    "ans_5 = roc_auc.mean()\n",
    "print('5. ROC AUC в кросс-валидации: {}'.format(ans_5))\n",
    "write_answer(5, ans_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Обучите логистическую регрессию на всей доступной вам выборке и выведите 5 наиболее важных для модели признаков (подумайте, какие именно признаки стоит считать такими). Вам могут пригодиться метод get_feature_names() или поле vocabulary_ у класса CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишите соответствующие двум самым важным для модели признакам слова из словаря через пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear').fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nword = 2\n",
    "# ans_6 = ' '.join([cv.get_feature_names()[i] for i in np.argpartition(-lr.coef_[0], nword)[:nword]])\n",
    "# print('Два самых важным для модели признакам слова :', ans_6)\n",
    "# write_answer(6, ans_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15246 0.4443 - great\n",
      "14159 0.5561 - fun\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# nword = 2\n",
    "# for i in np.argpartition(lr.coef_[0], -nword)[-nword:]:\n",
    "#     print('{:5d} {:.4f} - {}'.format(i, lr.coef_[0][i], cv.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf</th>\n",
       "      <th>cf_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>-0.782177</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37056</th>\n",
       "      <td>-0.636619</td>\n",
       "      <td>0.636619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>-0.592902</td>\n",
       "      <td>0.592902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>0.556066</td>\n",
       "      <td>0.556066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38417</th>\n",
       "      <td>-0.508179</td>\n",
       "      <td>0.508179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cf    cf_abs\n",
       "2954  -0.782177  0.782177\n",
       "37056 -0.636619  0.636619\n",
       "39195 -0.592902  0.592902\n",
       "14159  0.556066  0.556066\n",
       "38417 -0.508179  0.508179"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lr.coef_[0], columns=['cf'])\n",
    "df['cf_abs'] = abs(df.cf)\n",
    "ser = df.sort_values(by=['cf_abs'],  ascending=False)\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.7822 - bad\n",
      " -0.6366 - unfortunately\n",
      " -0.5929 - worst\n",
      "  0.5561 - fun\n",
      " -0.5082 - waste\n",
      " -0.5040 - nothing\n",
      " -0.4665 - script\n",
      " -0.4652 - awful\n",
      " -0.4632 - boring\n",
      " -0.4600 - only\n",
      "  0.4443 - great\n",
      " -0.4427 - plot\n",
      " -0.4421 - poor\n",
      " -0.4294 - reason\n",
      "  0.4267 - back\n",
      " -0.4172 - looks\n",
      " -0.3945 - mess\n",
      " -0.3928 - supposed\n",
      " -0.3854 - lame\n",
      "  0.3728 - quite\n"
     ]
    }
   ],
   "source": [
    "nword = 20 \n",
    "for i, cf in zip(ser.head(nword).index, ser.head(nword).cf.values):\n",
    "    print('{: >8.4f} - {}'.format(cf, cv.get_feature_names()[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Два самых важным для модели признакам слова : bad unfortunately\n"
     ]
    }
   ],
   "source": [
    "ans_6 = ' '.join([cv.get_feature_names()[i] for i in [2954, 37056]])\n",
    "print('6. Два самых важным для модели признакам слова :', ans_6)\n",
    "write_answer(6, ans_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:newpy]",
   "language": "python",
   "name": "conda-env-newpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
